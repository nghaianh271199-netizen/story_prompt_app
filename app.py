import os
import json
import streamlit as st
from groq import Groq

# üîë L·∫•y API key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
groq_api_key = os.getenv("GROQ_API_KEY")

if not groq_api_key:
    st.error("‚ùå Ch∆∞a c√≥ GROQ_API_KEY. V√†o Settings > Secrets ƒë·ªÉ th√™m.")
    st.stop()

# üöÄ T·∫°o client Groq
client = Groq(api_key=groq_api_key)

# -------------------------
# G·ªåI GROQ
# -------------------------
def call_groq(prompt, model="llama-3.1-8b-instant", max_tokens=2000, force_json=False):
    try:
        kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": max_tokens,
        }
        if force_json:
            kwargs["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"‚ùå L·ªói GPT/Groq: {str(e)}")
        return None

# -------------------------
# UI
# -------------------------
st.title("üìö Story ‚Üí Image Prompt Generator (Groq)")

uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n file k·ªãch b·∫£n (.txt)", type=["txt"])

if uploaded_file:
    story_text = uploaded_file.read().decode("utf-8")

    if st.button("üîç Ph√¢n t√≠ch & Sinh Prompt"):
        # -------------------------
        # Ph√¢n t√≠ch nh√¢n v·∫≠t
        # -------------------------
        with st.spinner("ƒêang ph√¢n t√≠ch nh√¢n v·∫≠t..."):
            profile_prompt = f"""
            Ph√¢n t√≠ch vƒÉn b·∫£n sau v√† li·ªát k√™ nh√¢n v·∫≠t ch√≠nh.
            Tr·∫£ v·ªÅ JSON **duy nh·∫•t**, kh√¥ng th√™m ch·ªØ n√†o kh√°c.

            VƒÉn b·∫£n:
            {story_text[:3000]}

            ƒê·ªãnh d·∫°ng JSON:
            {{
              "characters": [
                {{
                  "name": "T√™n nh√¢n v·∫≠t",
                  "description": "M√¥ t·∫£ ngo·∫°i h√¨nh + t√≠nh c√°ch"
                }}
              ]
            }}
            """

            profile_text = call_groq(profile_prompt, model="llama-3.1-8b-instant", force_json=True)

            profile_json = {}
            characters = []

            if profile_text:
                try:
                    profile_json = json.loads(profile_text)
                    characters = profile_json.get("characters", [])
                except Exception:
                    st.error("‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho nh√¢n v·∫≠t.")
                    st.text(profile_text)
                    characters = []

        # Hi·ªÉn th·ªã danh s√°ch nh√¢n v·∫≠t
        if characters:
            st.success("‚úÖ ƒê√£ ph√¢n t√≠ch nh√¢n v·∫≠t:")
            for c in characters:
                st.write(f"- **{c['name']}**: {c['description']}")
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y nh√¢n v·∫≠t, s·∫Ω ti·∫øp t·ª•c sinh prompt kh√¥ng c√≥ profile.")

        # -------------------------
        # Chia ƒëo·∫°n
        # -------------------------
        with st.spinner("ƒêang chia ƒëo·∫°n n·ªôi dung..."):
            split_prompt = f"""
            H√£y chia n·ªôi dung truy·ªán sau th√†nh c√°c ƒëo·∫°n ng·∫Øn (m·ªói ƒëo·∫°n ‚â§ 500 t·ª´).
            Xu·∫•t JSON theo m·∫´u:
            {{
              "chunks": [
                {{"id": 1, "text": "N·ªôi dung ƒëo·∫°n 1"}},
                {{"id": 2, "text": "N·ªôi dung ƒëo·∫°n 2"}}
              ]
            }}
            VƒÉn b·∫£n:
            {story_text[:8000]}
            """

            chunks_text = call_groq(split_prompt, model="llama-3.1-8b-instant", max_tokens=4000, force_json=True)

            chunks = []
            if chunks_text:
                try:
                    chunks_json = json.loads(chunks_text)
                    chunks = chunks_json.get("chunks", [])
                except Exception:
                    st.error("‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho chunks.")
                    st.text(chunks_text)
                    chunks = []
            else:
                st.error("‚ùå Kh√¥ng chia ƒëo·∫°n ƒë∆∞·ª£c.")

        # -------------------------
        # Sinh prompt cho t·ª´ng ƒëo·∫°n
        # -------------------------
        prompts = []
        for ch in chunks:
            char_context = f"Nh√¢n v·∫≠t: {characters}" if characters else "Kh√¥ng c√≥ nh√¢n v·∫≠t c·ª• th·ªÉ."
            scene_prompt = f"""
            D·ª±a tr√™n ƒëo·∫°n truy·ªán sau, h√£y vi·∫øt prompt ƒë·ªÉ v·∫Ω ·∫£nh minh h·ªça.
            {char_context}

            ƒêo·∫°n:
            {ch['text']}

            Xu·∫•t JSON:
            {{
              "id": {ch['id']},
              "prompt": "M√¥ t·∫£ prompt ·∫£nh"
            }}
            """
            scene_text = call_groq(scene_prompt, model="llama-3.1-8b-instant", max_tokens=1000, force_json=True)
            if scene_text:
                try:
                    scene_json = json.loads(scene_text)
                    prompts.append(scene_json)
                except Exception:
                    st.error(f"‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho ƒëo·∫°n {ch['id']}")
                    st.text(scene_text)

        # -------------------------
        # Xu·∫•t file k·∫øt qu·∫£
        # -------------------------
        if chunks and prompts:
            story_out = "\n\n".join([f"{c['id']}. {c['text']}" for c in chunks])
            prompt_out = "\n\n".join([f"{p['id']}. {p['prompt']}" for p in prompts])

            with open("story_chunks.txt", "w", encoding="utf-8") as f:
                f.write(story_out)

            with open("story_prompts.txt", "w", encoding="utf-8") as f:
                f.write(prompt_out)

            st.success("‚úÖ Ho√†n t·∫•t! ƒê√£ sinh file k·∫øt qu·∫£.")
            st.download_button("üì• T·∫£i file story_chunks.txt", story_out, file_name="story_chunks.txt")
            st.download_button("üì• T·∫£i file story_prompts.txt", prompt_out, file_name="story_prompts.txt")
