import os
import json
import streamlit as st
from groq import Groq

# üîë L·∫•y API key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
groq_api_key = os.getenv("GROQ_API_KEY")

if not groq_api_key:
    st.error("‚ùå Ch∆∞a c√≥ GROQ_API_KEY. V√†o Settings > Secrets ƒë·ªÉ th√™m.")
    st.stop()

# üöÄ T·∫°o client Groq
client = Groq(api_key=groq_api_key)

# -------------------------
# G·ªåI GROQ
# -------------------------
def call_groq(prompt, model="llama-3.1-8b-instant", max_tokens=2000):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=max_tokens,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"‚ùå L·ªói GPT/Groq: {str(e)}")
        return None

# -------------------------
# UI
# -------------------------
st.title("üìö Story ‚Üí Image Prompt Generator (Groq)")

uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n file k·ªãch b·∫£n (.txt)", type=["txt"])

if uploaded_file:
    story_text = uploaded_file.read().decode("utf-8")

    if st.button("üîç Ph√¢n t√≠ch & Sinh Prompt"):
        with st.spinner("ƒêang ph√¢n t√≠ch nh√¢n v·∫≠t..."):
            profile_prompt = f"""
            Ph√¢n t√≠ch vƒÉn b·∫£n sau v√† xu·∫•t JSON ch·ªâ ch·ª©a danh s√°ch nh√¢n v·∫≠t ch√≠nh.
            VƒÉn b·∫£n:
            {story_text[:3000]}  # c·∫Øt g·ªçn ƒë·ªÉ tr√°nh qu√° t·∫£i
            ƒê·ªãnh d·∫°ng JSON:
            {{
              "characters": [
                {{
                  "name": "T√™n nh√¢n v·∫≠t",
                  "description": "M√¥ t·∫£ ngo·∫°i h√¨nh + t√≠nh c√°ch"
                }}
              ]
            }}
            """

            profile_text = call_groq(profile_prompt, model="llama-3.1-8b-instant")

            profile_json = {}
            characters = []

            if profile_text:
                try:
                    profile_json = json.loads(profile_text)
                    characters = profile_json.get("characters", [])
                except Exception:
                    st.error("‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho nh√¢n v·∫≠t.")
                    st.text(profile_text)
                    profile_json = {}
                    characters = []
            else:
                st.error("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c profile t·ª´ Groq.")
                profile_json = {}
                characters = []

        # Hi·ªÉn th·ªã danh s√°ch nh√¢n v·∫≠t
        if characters:
            st.success("‚úÖ ƒê√£ ph√¢n t√≠ch nh√¢n v·∫≠t:")
            for c in characters:
                st.write(f"- **{c['name']}**: {c['description']}")
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y nh√¢n v·∫≠t n√†o.")

        # -------------------------
        # Chia ƒëo·∫°n
        # -------------------------
        with st.spinner("ƒêang chia ƒëo·∫°n n·ªôi dung..."):
            split_prompt = f"""
            H√£y chia n·ªôi dung truy·ªán sau th√†nh c√°c ƒëo·∫°n ng·∫Øn (m·ªói ƒëo·∫°n ‚â§ 500 t·ª´).
            Xu·∫•t JSON theo m·∫´u:
            {{
              "chunks": [
                {{"id": 1, "text": "N·ªôi dung ƒëo·∫°n 1"}},
                {{"id": 2, "text": "N·ªôi dung ƒëo·∫°n 2"}}
              ]
            }}
            VƒÉn b·∫£n:
            {story_text[:8000]}
            """

            chunks_text = call_groq(split_prompt, model="llama-3.1-8b-instant", max_tokens=4000)

            chunks = []
            if chunks_text:
                try:
                    chunks_json = json.loads(chunks_text)
                    chunks = chunks_json.get("chunks", [])
                except Exception:
                    st.error("‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho chunks.")
                    st.text(chunks_text)
                    chunks = []
            else:
                st.error("‚ùå Kh√¥ng chia ƒëo·∫°n ƒë∆∞·ª£c.")

        # -------------------------
        # Sinh prompt cho t·ª´ng ƒëo·∫°n
        # -------------------------
        prompts = []
        for ch in chunks:
            scene_prompt = f"""
            D·ª±a tr√™n ƒëo·∫°n truy·ªán sau, h√£y vi·∫øt prompt ƒë·ªÉ v·∫Ω ·∫£nh minh h·ªça.
            Gi·ªØ cho nh√¢n v·∫≠t ƒë·ªìng nh·∫•t v·ªõi m√¥ t·∫£ sau:
            {characters}

            ƒêo·∫°n:
            {ch['text']}

            Xu·∫•t JSON:
            {{
              "id": {ch['id']},
              "prompt": "M√¥ t·∫£ prompt ·∫£nh"
            }}
            """
            scene_text = call_groq(scene_prompt, model="llama-3.1-8b-instant", max_tokens=1000)
            if scene_text:
                try:
                    scene_json = json.loads(scene_text)
                    prompts.append(scene_json)
                except Exception:
                    st.error(f"‚ö†Ô∏è GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá cho ƒëo·∫°n {ch['id']}")
                    st.text(scene_text)

        # -------------------------
        # Xu·∫•t file k·∫øt qu·∫£
        # -------------------------
        if chunks and prompts:
            story_out = "\n\n".join([f"{c['id']}. {c['text']}" for c in chunks])
            prompt_out = "\n\n".join([f"{p['id']}. {p['prompt']}" for p in prompts])

            with open("story_chunks.txt", "w", encoding="utf-8") as f:
                f.write(story_out)

            with open("story_prompts.txt", "w", encoding="utf-8") as f:
                f.write(prompt_out)

            st.success("‚úÖ Ho√†n t·∫•t! ƒê√£ sinh file k·∫øt qu·∫£.")
            st.download_button("üì• T·∫£i file story_chunks.txt", story_out, file_name="story_chunks.txt")
            st.download_button("üì• T·∫£i file story_prompts.txt", prompt_out, file_name="story_prompts.txt")
