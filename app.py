import streamlit as st
from groq import Groq
import os
import json

# Kh·ªüi t·∫°o client Groq
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

def call_gpt(prompt, model="llama3-70b-8192", temperature=0.7):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
        )
        content = response.choices[0].message.content.strip()
        return content
    except Exception as e:
        st.error(f"L·ªói GPT/Groq: {e}")
        return None

st.title("üìñ Story to Prompt Generator (Groq)")

uploaded_file = st.file_uploader("T·∫£i l√™n file k·ªãch b·∫£n (.txt)", type=["txt"])

if uploaded_file is not None:
    story_text = uploaded_file.read().decode("utf-8")

    if st.button("Ph√¢n t√≠ch v√† sinh prompt"):
        with st.spinner("ƒêang ph√¢n t√≠ch c√¢u chuy·ªán..."):

            # -------- B∆Ø·ªöC 1: Chia ƒëo·∫°n v·ªõi model nh·ªè (llama3-8b) --------
            split_prompt = f"""
            H√£y chia n·ªôi dung d∆∞·ªõi ƒë√¢y th√†nh c√°c ƒëo·∫°n nh·ªè h·ª£p l√Ω theo ng·ªØ c·∫£nh.
            Ch·ªâ c·∫ßn xu·∫•t JSON:
            {{
              "segments": [
                {{"id": 1, "text": "..." }},
                {{"id": 2, "text": "..." }}
              ]
            }}

            VƒÉn b·∫£n:
            {story_text}
            """

            split_result = call_gpt(split_prompt, model="llama3-8b-8192")

            if not split_result:
                st.error("‚ùå Kh√¥ng chia ƒëo·∫°n ƒë∆∞·ª£c.")
            else:
                try:
                    segments = json.loads(split_result)["segments"]
                except:
                    st.error("JSON chia ƒëo·∫°n kh√¥ng h·ª£p l·ªá.")
                    segments = []

                # -------- B∆Ø·ªöC 2: Sinh prompt cho t·ª´ng ƒëo·∫°n b·∫±ng model m·∫°nh (llama3-70b) --------
                results = {"segments": []}
                for seg in segments:
                    prompt_prompt = f"""
                    ƒê√¢y l√† m·ªôt ƒëo·∫°n truy·ªán:
                    {seg['text']}

                    Nhi·ªám v·ª•: vi·∫øt prompt ƒë·ªÉ sinh ·∫£nh minh h·ªça ƒëo·∫°n n√†y.
                    Y√™u c·∫ßu:
                    - Nh√¢n v·∫≠t ƒë·ªìng nh·∫•t v·ªõi c√°c ƒëo·∫°n kh√°c
                    - B·ªëi c·∫£nh h·ª£p l√Ω, logic
                    - Vi·∫øt prompt ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu

                    Xu·∫•t JSON:
                    {{
                      "id": {seg['id']},
                      "text": "{seg['text']}",
                      "prompt": "..."
                    }}
                    """
                    out = call_gpt(prompt_prompt, model="llama3-70b-8192")
                    try:
                        obj = json.loads(out)
                        results["segments"].append(obj)
                    except:
                        results["segments"].append({
                            "id": seg["id"],
                            "text": seg["text"],
                            "prompt": out
                        })

                st.success("‚úÖ Ho√†n t·∫•t ph√¢n t√≠ch v√† sinh prompt!")

                for seg in results["segments"]:
                    st.subheader(f"ƒêo·∫°n {seg['id']}")
                    st.write(seg["text"])
                    st.code(seg["prompt"], language="markdown")

                # Xu·∫•t file JSON
                json_str = json.dumps(results, ensure_ascii=False, indent=2)
                st.download_button("‚¨áÔ∏è T·∫£i JSON", data=json_str, file_name="story_segments.json")

                # Xu·∫•t file TXT
                txt_out = ""
                for seg in results["segments"]:
                    txt_out += f"ƒêo·∫°n {seg['id']}:\n{seg['text']}\nPrompt: {seg['prompt']}\n\n"
                st.download_button("‚¨áÔ∏è T·∫£i TXT", data=txt_out, file_name="story_segments.txt")
